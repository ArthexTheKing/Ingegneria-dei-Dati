La Backpropagation Ã¨ l'algoritmo centrale per l'addestramento delle reti neurali profonde. Il processo si svolge in due fasi: forward pass (calcolo dell'output) e backward pass. Nel backward pass, l'errore (o loss) viene propagato all'indietro per calcolare il gradiente della funzione di costo rispetto ai pesi della rete, che vengono poi aggiornati tramite un ottimizzatore (es. Adam o SGD).
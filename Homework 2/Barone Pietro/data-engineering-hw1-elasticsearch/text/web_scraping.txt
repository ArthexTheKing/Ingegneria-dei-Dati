Il Web Scraping (o estrazione di dati web) è la tecnica che utilizza programmi automatizzati (bot o crawler) per estrarre grandi quantità di dati da siti web. Il processo implica il fetching della pagina web e l'analisi del suo contenuto (HTML parsing) per isolare e copiare i dati desiderati, spesso trasformando dati non strutturati in formati strutturati come fogli di calcolo o database. È impiegato per il monitoraggio dei prezzi, la raccolta di lead, l'indicizzazione dei motori di ricerca e la ricerca scientifica. Tuttavia, deve essere eseguito nel rispetto delle leggi e dei termini di servizio dei siti.
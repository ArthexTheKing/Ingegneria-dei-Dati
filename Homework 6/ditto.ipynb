{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RlIZ-5Z8gN4r",
        "outputId": "fc99f566-4d8f-42fa-c2cc-36afa242c7c8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "fatal: destination path 'FAIR-DA4ER' already exists and is not an empty directory.\n",
            "/content/FAIR-DA4ER/ditto/FAIR-DA4ER\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 1)) (4.4.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 2)) (2.0.2)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 3)) (2025.11.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 4)) (1.16.3)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 5)) (0.2.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 6)) (1.6.1)\n",
            "Requirement already satisfied: spacy in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 7)) (3.8.11)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 8)) (2.9.0+cu128)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 9)) (5.0.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 10)) (4.67.3)\n",
            "Requirement already satisfied: jsonlines in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 11)) (4.0.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 12)) (3.9.1)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 13)) (2.6.4)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 14)) (5.29.6)\n",
            "Requirement already satisfied: timm in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 15)) (1.0.24)\n",
            "Requirement already satisfied: wheel in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 16)) (0.46.3)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 17)) (2.2.2)\n",
            "Requirement already satisfied: wordfreq in /usr/local/lib/python3.12/dist-packages (from -r requirements.txt (line 19)) (3.1.1)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim->-r requirements.txt (line 1)) (7.5.0)\n",
            "Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (1.5.3)\n",
            "Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn->-r requirements.txt (line 6)) (3.6.0)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (1.0.15)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.13)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (3.0.12)\n",
            "Requirement already satisfied: thinc<8.4.0,>=8.3.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (8.3.10)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (2.5.2)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (0.4.3)\n",
            "Requirement already satisfied: typer-slim<1.0.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (0.21.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (2.32.4)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (2.12.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (3.1.6)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (75.2.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from spacy->-r requirements.txt (line 7)) (26.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.20.3)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (4.15.0)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (1.14.0)\n",
            "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.6.1)\n",
            "Requirement already satisfied: fsspec>=0.8.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (2025.3.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (9.10.2.21)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.8.4.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.8.4.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.3.3.83 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (11.3.3.83)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.9.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (10.3.9.90)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.7.3.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (11.7.3.90)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.5.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.5.8.93)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (0.7.1)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (2.27.5)\n",
            "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.3.20)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.8.90 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.8.90)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.8.93 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (12.8.93)\n",
            "Requirement already satisfied: nvidia-cufile-cu12==1.13.1.3 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (1.13.1.3)\n",
            "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch->-r requirements.txt (line 8)) (3.5.0)\n",
            "Requirement already satisfied: huggingface-hub<2.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 9)) (1.4.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 9)) (6.0.3)\n",
            "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 9)) (0.22.2)\n",
            "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from transformers->-r requirements.txt (line 9)) (0.7.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonlines->-r requirements.txt (line 11)) (25.4.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.12/dist-packages (from nltk->-r requirements.txt (line 12)) (8.3.1)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.12/dist-packages (from timm->-r requirements.txt (line 15)) (0.24.0+cu128)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 17)) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 17)) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->-r requirements.txt (line 17)) (2025.3)\n",
            "Requirement already satisfied: ftfy>=6.1 in /usr/local/lib/python3.12/dist-packages (from wordfreq->-r requirements.txt (line 19)) (6.3.1)\n",
            "Requirement already satisfied: langcodes>=3.0 in /usr/local/lib/python3.12/dist-packages (from wordfreq->-r requirements.txt (line 19)) (3.5.1)\n",
            "Requirement already satisfied: locate<2.0.0,>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from wordfreq->-r requirements.txt (line 19)) (1.1.1)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from wordfreq->-r requirements.txt (line 19)) (1.1.2)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.12/dist-packages (from ftfy>=6.1->wordfreq->-r requirements.txt (line 19)) (0.5.3)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->-r requirements.txt (line 9)) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->-r requirements.txt (line 9)) (0.28.1)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface-hub<2.0,>=1.3.0->transformers->-r requirements.txt (line 9)) (1.5.4)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 7)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 7)) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy->-r requirements.txt (line 7)) (0.4.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->-r requirements.txt (line 17)) (1.17.0)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 7)) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 7)) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 7)) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.13.0->spacy->-r requirements.txt (line 7)) (2026.1.4)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim->-r requirements.txt (line 1)) (2.1.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch->-r requirements.txt (line 8)) (1.3.0)\n",
            "Requirement already satisfied: blis<1.4.0,>=1.3.0 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 7)) (1.3.3)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.12/dist-packages (from thinc<8.4.0,>=8.3.4->spacy->-r requirements.txt (line 7)) (0.1.5)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from weasel<0.5.0,>=0.4.2->spacy->-r requirements.txt (line 7)) (0.23.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->spacy->-r requirements.txt (line 7)) (3.0.3)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from torchvision->timm->-r requirements.txt (line 15)) (11.3.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->-r requirements.txt (line 9)) (4.12.1)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->-r requirements.txt (line 9)) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface-hub<2.0,>=1.3.0->transformers->-r requirements.txt (line 9)) (0.16.0)\n",
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.12/dist-packages (2.6.4)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (26.0)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.12/dist-packages (from tensorboardX) (5.29.6)\n"
          ]
        }
      ],
      "source": [
        "# Clona il repository indicato nella consegna\n",
        "!git clone https://github.com/MarcoNapoleone/FAIR-DA4ER.git\n",
        "%cd FAIR-DA4ER\n",
        "\n",
        "# Installa le dipendenze (Ditto richiede librerie specifiche)\n",
        "!pip install -r requirements.txt\n",
        "!pip install tensorboardX\n",
        "# Installa NVIDIA Apex (opzionale ma consigliato per Ditto, se fallisce procedi senza o usa fp16=False)\n",
        "# Nota: L'installazione di Apex su Colab può essere rognosa, spesso Ditto funziona anche senza se configurato bene."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pk7XqSKNjlpm",
        "outputId": "fae7311b-3acb-48a2-cf4e-9f5fd458ce02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('stopwords')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoghIPwEgYP2",
        "outputId": "79b58291-d862-46a1-ea75-73cc98aeb2c2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FAIR-DA4ER/ditto\n",
            "test.txt  train.txt  val.txt\n"
          ]
        }
      ],
      "source": [
        "# Assicurati di essere nella cartella di Ditto\n",
        "%cd /content/FAIR-DA4ER/ditto\n",
        "\n",
        "# Crea la cartella per i dati\n",
        "!mkdir -p data/vehicles\n",
        "\n",
        "# Sposta e rinomina i file caricati nella cartella corretta\n",
        "!cp /content/ditto_train.txt data/vehicles/train.txt\n",
        "!cp /content/ditto_val.txt   data/vehicles/val.txt\n",
        "!cp /content/ditto_test.txt  data/vehicles/test.txt\n",
        "\n",
        "# Verifica che i file siano al posto giusto\n",
        "!ls data/vehicles"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IKGRxbP9_FXD",
        "outputId": "da538cf5-fe13-4871-efb3-aaef20a65002"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FAIR-DA4ER/ditto\n",
            "✔ Configurazione 'vehicles' aggiunta con successo!\n"
          ]
        }
      ],
      "source": [
        "# --- CELLA MANCANTE: AGGIORNAMENTO CONFIGS.JSON ---\n",
        "import json\n",
        "import os\n",
        "\n",
        "# Assicuriamoci di essere nella cartella giusta\n",
        "%cd /content/FAIR-DA4ER/ditto\n",
        "\n",
        "config_path = 'configs.json'\n",
        "\n",
        "# 1. Leggi la configurazione esistente\n",
        "with open(config_path, 'r') as f:\n",
        "    data = json.load(f)\n",
        "\n",
        "# 2. Definisci la nuova configurazione per i veicoli\n",
        "new_config = {\n",
        "    \"name\": \"vehicles\",\n",
        "    \"task_type\": \"classification\",\n",
        "    \"vocab\": [\"0\", \"1\"],\n",
        "    \"trainset\": \"data/vehicles/train.txt\",\n",
        "    \"validset\": \"data/vehicles/val.txt\",\n",
        "    \"testset\": \"data/vehicles/test.txt\"\n",
        "}\n",
        "\n",
        "# 3. Aggiungi alla lista (o dizionario) evitando duplicati\n",
        "if isinstance(data, list):\n",
        "    # Rimuovi eventuali vecchie versioni per non fare pasticci\n",
        "    data = [entry for entry in data if entry.get('name') != 'vehicles']\n",
        "    data.append(new_config)\n",
        "else:\n",
        "    data['vehicles'] = new_config\n",
        "\n",
        "# 4. Salva le modifiche\n",
        "with open(config_path, 'w') as f:\n",
        "    json.dump(data, f, indent=4)\n",
        "\n",
        "print(\"✔ Configurazione 'vehicles' aggiunta con successo!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2dstUpNKkYz4",
        "outputId": "468de0e4-9f55-4296-9c09-3fc94d361de3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/FAIR-DA4ER/ditto/ditto_light/dataset.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/FAIR-DA4ER/ditto/ditto_light/dataset.py\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from transformers import AutoTokenizer\n",
        "import json\n",
        "\n",
        "def get_tokenizer(lm):\n",
        "    return AutoTokenizer.from_pretrained(lm)\n",
        "\n",
        "class DittoDataset(Dataset):\n",
        "    def __init__(self, path, max_len=256, lm='distilbert', da=None, size=None):\n",
        "        self.tokenizer = get_tokenizer(lm)\n",
        "        self.pairs = []\n",
        "        self.labels = []\n",
        "        self.max_len = max_len\n",
        "        self.size = size\n",
        "\n",
        "        # Logica Tab Robusta\n",
        "        with open(path) as f:\n",
        "            for line in f:\n",
        "                parts = line.strip().split('\\t')\n",
        "                if len(parts) < 3: continue\n",
        "                if len(parts) == 3:\n",
        "                    s1, s2, label = parts\n",
        "                else:\n",
        "                    s1 = parts[0]\n",
        "                    label = parts[-1]\n",
        "                    s2 = \" \".join(parts[1:-1])\n",
        "                self.pairs.append((s1, s2))\n",
        "                self.labels.append(int(label))\n",
        "\n",
        "        if size is not None and size > 0:\n",
        "            self.pairs = self.pairs[:size]\n",
        "            self.labels = self.labels[:size]\n",
        "\n",
        "        self.da = da\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        x1, x2 = self.pairs[idx]\n",
        "        if self.da is not None:\n",
        "            x1, x2 = self.da.transform(x1, x2)\n",
        "\n",
        "        encoded_inputs = self.tokenizer(x1, x2,\n",
        "                                      max_length=self.max_len,\n",
        "                                      padding='max_length',\n",
        "                                      truncation=True)\n",
        "\n",
        "        item = {key: torch.tensor(val) for key, val in encoded_inputs.items()}\n",
        "        item['labels'] = torch.tensor(self.labels[idx])\n",
        "        return item\n",
        "\n",
        "    # --- FIX CRUCIALE QUI SOTTO ---\n",
        "    def pad(self, batch):\n",
        "        # Restituiamo una TUPLA di 3 elementi come si aspetta ditto.py (x1, x2, y)\n",
        "        # x1 = input_ids, x2 = attention_mask, y = labels\n",
        "\n",
        "        input_ids = torch.stack([b['input_ids'] for b in batch])\n",
        "        attention_mask = torch.stack([b['attention_mask'] for b in batch])\n",
        "        labels = torch.stack([b['labels'] for b in batch])\n",
        "\n",
        "        return input_ids, attention_mask, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z-AO3SlL5suN",
        "outputId": "4501b411-126a-4a3b-95e8-44e43c2cb954"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✔ Patch applicata a ditto.py! Ora la validazione funzionerà.\n"
          ]
        }
      ],
      "source": [
        "# Patch per ditto_light/ditto.py\n",
        "# Corregge la funzione 'evaluate' per gestire input_ids e attention_mask separati\n",
        "\n",
        "file_path = '/content/FAIR-DA4ER/ditto/ditto_light/ditto.py'\n",
        "\n",
        "with open(file_path, 'r') as f:\n",
        "    lines = f.readlines()\n",
        "\n",
        "new_lines = []\n",
        "for line in lines:\n",
        "    # 1. Correggiamo l'unpacking: da \"x, y\" a \"x1, x2, y\"\n",
        "    if 'x, y = batch' in line:\n",
        "        indent = line.split('x, y')[0]\n",
        "        new_lines.append(f'{indent}x1, x2, y = batch\\n')\n",
        "\n",
        "    # 2. Correggiamo lo spostamento su GPU\n",
        "    elif 'x = x.to(device)' in line:\n",
        "        indent = line.split('x =')[0]\n",
        "        new_lines.append(f'{indent}x1 = x1.to(device)\\n')\n",
        "        new_lines.append(f'{indent}x2 = x2.to(device)\\n')\n",
        "\n",
        "    # 3. Correggiamo la chiamata al modello\n",
        "    elif 'logits = model(x)' in line:\n",
        "        new_lines.append(line.replace('model(x)', 'model(x1, x2)'))\n",
        "\n",
        "    else:\n",
        "        new_lines.append(line)\n",
        "\n",
        "with open(file_path, 'w') as f:\n",
        "    f.writelines(new_lines)\n",
        "\n",
        "print(\"✔ Patch applicata a ditto.py! Ora la validazione funzionerà.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "nmIDeG5Xj17r",
        "outputId": "539bc16a-c59a-4a85-a4e5-cd3d756538db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FAIR-DA4ER/ditto\n",
            "Running cuda\n",
            "Warning: You are sending unauthenticated requests to the HF Hub. Please set a HF_TOKEN to enable higher rate limits and faster downloads.\n",
            "Loading weights: 100% 100/100 [00:00<00:00, 1363.62it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]\n",
            "\u001b[1mDistilBertModel LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "vocab_transform.bias    | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_projector.bias    | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_layer_norm.bias   | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_layer_norm.weight | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_transform.weight  | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "step: 0, loss: 0.6919939517974854\n",
            "step: 10, loss: 0.6929281949996948\n",
            "step: 20, loss: 0.7240093946456909\n",
            "step: 30, loss: 0.6856732368469238\n",
            "step: 40, loss: 0.6813648343086243\n",
            "step: 50, loss: 0.6941933035850525\n",
            "step: 60, loss: 0.680903434753418\n",
            "step: 70, loss: 0.6397150158882141\n",
            "step: 80, loss: 0.5838555097579956\n",
            "step: 90, loss: 0.35289502143859863\n",
            "step: 100, loss: 0.3672097325325012\n",
            "step: 110, loss: 0.34672901034355164\n",
            "step: 120, loss: 0.172319695353508\n",
            "step: 130, loss: 0.3212348222732544\n",
            "step: 140, loss: 0.35287147760391235\n",
            "step: 150, loss: 0.05967139080166817\n",
            "step: 160, loss: 0.17710593342781067\n",
            "step: 170, loss: 0.03126642107963562\n",
            "step: 180, loss: 0.6324297189712524\n",
            "step: 190, loss: 0.19793301820755005\n",
            "step: 200, loss: 0.029664238914847374\n",
            "step: 210, loss: 0.33249586820602417\n",
            "step: 220, loss: 0.15085215866565704\n",
            "step: 230, loss: 0.451572060585022\n",
            "step: 240, loss: 0.042722027748823166\n",
            "step: 250, loss: 0.07961148023605347\n",
            "step: 260, loss: 0.01462136022746563\n",
            "step: 270, loss: 0.048292603343725204\n",
            "step: 280, loss: 0.06920367479324341\n",
            "step: 290, loss: 0.15341147780418396\n",
            "step: 300, loss: 0.2808648347854614\n",
            "step: 310, loss: 0.2594098448753357\n",
            "step: 320, loss: 0.14722713828086853\n",
            "step: 330, loss: 0.18217137455940247\n",
            "step: 340, loss: 0.0014647841453552246\n",
            "step: 350, loss: 0.3704010248184204\n",
            "step: 360, loss: 0.14350247383117676\n",
            "step: 370, loss: 0.1042332649230957\n",
            "step: 380, loss: 0.2213379293680191\n",
            "step: 390, loss: 0.03683310002088547\n",
            "step: 400, loss: 0.2143743932247162\n",
            "step: 410, loss: 0.09777483344078064\n",
            "step: 420, loss: 0.25588545203208923\n",
            "step: 430, loss: 0.15066339075565338\n",
            "step: 440, loss: 0.09754005074501038\n",
            "step: 450, loss: 0.4853857159614563\n",
            "step: 460, loss: 0.06595917046070099\n",
            "step: 470, loss: 0.006387963891029358\n",
            "step: 480, loss: 0.07051710039377213\n",
            "step: 490, loss: 0.0013801765162497759\n",
            "step: 500, loss: 0.06529440730810165\n",
            "step: 510, loss: 0.0600394532084465\n",
            "step: 520, loss: 0.11514496058225632\n",
            "step: 530, loss: 0.2782292366027832\n",
            "step: 540, loss: 0.32308271527290344\n",
            "step: 550, loss: 9.139753819908947e-05\n",
            "step: 560, loss: 0.16614574193954468\n",
            "step: 570, loss: 0.4995020031929016\n",
            "step: 580, loss: 0.0019684522412717342\n",
            "step: 590, loss: 0.059321578592061996\n",
            "step: 600, loss: 0.04994143918156624\n",
            "step: 610, loss: 0.10753445327281952\n",
            "step: 620, loss: 0.00015369217726401985\n",
            "step: 630, loss: 0.07481200248003006\n",
            "step: 640, loss: 0.08039984107017517\n",
            "step: 650, loss: 0.17933274805545807\n",
            "step: 660, loss: 0.549480676651001\n",
            "step: 670, loss: 0.014851942658424377\n",
            "epoch 1: dev_f1=0.942565754159957, f1=0.9438802779262426, best_f1=0.9438802779262426\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FAIR-DA4ER/ditto\n",
        "\n",
        "# Ho rimosso --fp16 per sicurezza\n",
        "!python train_ditto.py \\\n",
        "  --task vehicles \\\n",
        "  --batch_size 16 \\\n",
        "  --max_len 256 \\\n",
        "  --lr 3e-5 \\\n",
        "  --n_epochs 1 \\\n",
        "  --save_model \\\n",
        "  --lm distilbert-base-uncased"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "d9zLdqPP3g-x",
        "outputId": "1d72d851-96dd-4cf8-e618-63c7d5e9b776"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Overwriting /content/FAIR-DA4ER/ditto/matcher.py\n"
          ]
        }
      ],
      "source": [
        "%%writefile /content/FAIR-DA4ER/ditto/matcher.py\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import os\n",
        "import numpy as np\n",
        "import sys\n",
        "import json\n",
        "import argparse\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Import interni\n",
        "from ditto_light.ditto import DittoModel\n",
        "from ditto_light.dataset import DittoDataset\n",
        "\n",
        "def evaluate(model, iterator, threshold=None):\n",
        "    model.eval()\n",
        "    all_y = []\n",
        "    all_probs = []\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for batch in tqdm(iterator):\n",
        "            x1, x2, y = batch\n",
        "\n",
        "            if torch.cuda.is_available():\n",
        "                x1 = x1.cuda()\n",
        "                x2 = x2.cuda()\n",
        "                y = y.cuda()\n",
        "\n",
        "            logits = model(x1, x2)\n",
        "            probs = logits.softmax(dim=1)[:, 1]\n",
        "\n",
        "            all_probs += probs.cpu().numpy().tolist()\n",
        "            all_y += y.cpu().numpy().tolist()\n",
        "\n",
        "    if threshold is None:\n",
        "        threshold = 0.5\n",
        "\n",
        "    pred = [1 if p > threshold else 0 for p in all_probs]\n",
        "\n",
        "    f1 = f1_score(all_y, pred)\n",
        "    p = precision_score(all_y, pred)\n",
        "    r = recall_score(all_y, pred)\n",
        "\n",
        "    return f1, p, r, threshold\n",
        "\n",
        "def main():\n",
        "    parser = argparse.ArgumentParser()\n",
        "    parser.add_argument(\"--task\", type=str, default=\"vehicles\")\n",
        "    parser.add_argument(\"--input_path\", type=str, default=\"data/vehicles/test.txt\")\n",
        "    parser.add_argument(\"--output_path\", type=str, default=\"output/result.jsonl\")\n",
        "    parser.add_argument(\"--model_path\", type=str, default=\"checkpoints/\")\n",
        "    parser.add_argument(\"--lm\", type=str, default=\"distilbert-base-uncased\")\n",
        "    parser.add_argument(\"--max_len\", type=int, default=256)\n",
        "    parser.add_argument(\"--use_gpu\", action=\"store_true\")\n",
        "    parser.add_argument(\"--fp16\", action=\"store_true\")\n",
        "    parser.add_argument(\"--batch_size\", type=int, default=64)\n",
        "\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    device = 'cuda' if args.use_gpu and torch.cuda.is_available() else 'cpu'\n",
        "\n",
        "    print(f\"Loading model architecture ({args.lm})...\")\n",
        "    model = DittoModel(device=device, lm=args.lm)\n",
        "\n",
        "    # Gestione percorso file\n",
        "    if os.path.isdir(args.model_path):\n",
        "        files = [f for f in os.listdir(args.model_path) if f.endswith('.pt')]\n",
        "        if not files:\n",
        "            print(f\"❌ Nessun file .pt trovato in {args.model_path}\")\n",
        "            return\n",
        "        checkpoint_path = os.path.join(args.model_path, files[0])\n",
        "    else:\n",
        "        checkpoint_path = args.model_path\n",
        "\n",
        "    print(f\"Loading weights from: {checkpoint_path}\")\n",
        "\n",
        "    # --- FIX QUI SOTTO: Caricamento intelligente ---\n",
        "    checkpoint = torch.load(checkpoint_path, map_location=device)\n",
        "\n",
        "    if 'model' in checkpoint:\n",
        "        # Se il file contiene lo stato completo del training, estraiamo solo la parte 'model'\n",
        "        print(\"Extracting model weights from training checkpoint...\")\n",
        "        model.load_state_dict(checkpoint['model'])\n",
        "    else:\n",
        "        # Altrimenti carichiamo direttamente (vecchio formato)\n",
        "        model.load_state_dict(checkpoint)\n",
        "    # -----------------------------------------------\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    print(f\"Loading data from {args.input_path}...\")\n",
        "    test_dataset = DittoDataset(args.input_path, max_len=args.max_len, lm=args.lm)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False,\n",
        "                             num_workers=0, collate_fn=test_dataset.pad)\n",
        "\n",
        "    print(\"Running inference...\")\n",
        "    f1, p, r, th = evaluate(model, test_loader)\n",
        "\n",
        "    print(\"=\"*30)\n",
        "    print(f\"✅ RISULTATI FINALI (Punto 4.H)\")\n",
        "    print(f\"Precision: {p:.4f}\")\n",
        "    print(f\"Recall:    {r:.4f}\")\n",
        "    print(f\"F1 Score:  {f1:.4f}\")\n",
        "    print(\"=\"*30)\n",
        "\n",
        "    os.makedirs(os.path.dirname(args.output_path), exist_ok=True)\n",
        "    with open(args.output_path, 'w') as f:\n",
        "        json.dump({\"precision\": p, \"recall\": r, \"f1\": f1}, f)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "B_IQyV-J8V-N",
        "outputId": "237af8de-e803-41c1-d8ac-737ce7c5b1c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/FAIR-DA4ER/ditto\n",
            "Loading model architecture (distilbert-base-uncased)...\n",
            "Loading weights: 100% 100/100 [00:00<00:00, 930.84it/s, Materializing param=transformer.layer.5.sa_layer_norm.weight]\n",
            "\u001b[1mDistilBertModel LOAD REPORT\u001b[0m from: distilbert-base-uncased\n",
            "Key                     | Status     |  | \n",
            "------------------------+------------+--+-\n",
            "vocab_layer_norm.bias   | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_projector.bias    | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_layer_norm.weight | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_transform.bias    | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "vocab_transform.weight  | \u001b[38;5;208mUNEXPECTED\u001b[0m |  | \n",
            "\n",
            "\u001b[3mNotes:\n",
            "- \u001b[38;5;208mUNEXPECTED\u001b[0m\u001b[3m\t:can be ignored when loading from different task/architecture; not ok if you expect identical arch.\u001b[0m\n",
            "Loading weights from: checkpoints/vehicles/model.pt\n",
            "Extracting model weights from training checkpoint...\n",
            "Loading data from data/vehicles/test.txt...\n",
            "Running inference...\n",
            "100% 57/57 [01:34<00:00,  1.65s/it]\n",
            "==============================\n",
            "✅ RISULTATI FINALI (Punto 4.H)\n",
            "Precision: 0.9730\n",
            "Recall:    0.8817\n",
            "F1 Score:  0.9251\n",
            "==============================\n"
          ]
        }
      ],
      "source": [
        "%cd /content/FAIR-DA4ER/ditto\n",
        "\n",
        "!python matcher.py \\\n",
        "  --task vehicles \\\n",
        "  --input_path data/vehicles/test.txt \\\n",
        "  --model_path checkpoints/vehicles/model.pt \\\n",
        "  --lm distilbert-base-uncased \\\n",
        "  --max_len 256 \\\n",
        "  --use_gpu"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}